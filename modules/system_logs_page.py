import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
from database.queries import get_system_logs, get_system_stats, get_error_logs, get_performance_metrics
from components.common import render_footer

def render_system_logs():
    """æ¸²æŸ“ç³»ç»Ÿæ—¥å¿—é¡µé¢"""
    st.title("ğŸ“‹ ç³»ç»Ÿè¿è¡Œæ—¥å¿—")
    
    # ç³»ç»ŸçŠ¶æ€æ¦‚è§ˆ
    render_system_status()
    
    st.divider()
    
    # ä¸»è¦åŠŸèƒ½æ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“Š ç³»ç»Ÿæ¦‚è§ˆ", "ğŸ“ è¿è¡Œæ—¥å¿—", "âš ï¸ å¼‚å¸¸ç›‘æ§", "ğŸ“ˆ æ€§èƒ½åˆ†æ", "ğŸ” æ—¥å¿—æŸ¥è¯¢"])
    
    with tab1:
        render_system_overview()
    
    with tab2:
        render_runtime_logs()
    
    with tab3:
        render_error_monitoring()
    
    with tab4:
        render_performance_analysis()
    
    with tab5:
        render_log_search()
    
    render_footer()

def render_system_status():
    """æ¸²æŸ“ç³»ç»ŸçŠ¶æ€æ¦‚è§ˆ"""
    stats = get_system_stats()
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        status_color = "ğŸŸ¢" if stats.get('db_status') == 'æ­£å¸¸' else "ğŸ”´"
        st.metric(
            label=f"{status_color} æ•°æ®åº“è¿æ¥",
            value=stats.get('db_status', 'æœªçŸ¥'),
            delta=f"è¿æ¥æ± : {stats.get('db_pool_size', 0)}/{stats.get('db_pool_max', 0)}"
        )
    with col2:
        st.metric(
            label="ğŸ”„ é‡‡é›†æœåŠ¡",
            value=f"{stats.get('collection_delay', 0)}ms",
            delta=f"{stats.get('delay_change', 0)}ms è¾ƒä¸Šå°æ—¶"
        )
    with col3:
        alert_color = "ğŸŸ¡" if stats.get('error_count', 0) > 0 else "ğŸŸ¢"
        st.metric(
            label=f"{alert_color} ä»Šæ—¥å¼‚å¸¸",
            value=stats.get('error_count', 0),
            delta=f"-{stats.get('resolved_errors', 0)} å·²å¤„ç†"
        )
    with col4:
        st.metric(
            label="ğŸ“Š æ•°æ®åå",
            value=f"{stats.get('data_throughput', 0)}/min",
            delta=f"{stats.get('throughput_change', 0)}% è¾ƒæ˜¨æ—¥"
        )

def render_system_overview():
    """æ¸²æŸ“ç³»ç»Ÿæ¦‚è§ˆ"""
    st.subheader("ğŸ“Š ç³»ç»Ÿæ•´ä½“çŠ¶æ€")
    
    # æœåŠ¡çŠ¶æ€ç›‘æ§
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("##### æœåŠ¡çŠ¶æ€")
        services = get_service_status()
        if not services.empty:
            fig_services = go.Figure()
            
            # åˆ›å»ºçŠ¶æ€æŒ‡ç¤ºå™¨
            for i, service in services.iterrows():
                status_value = 1 if service['status'] == 'è¿è¡Œä¸­' else 0
                color = '#2E8B57' if service['status'] == 'è¿è¡Œä¸­' else '#DC143C'
                
                fig_services.add_trace(go.Indicator(
                    mode="number+gauge+delta",
                    value=status_value,
                    domain={'x': [0, 1], 'y': [i/services.shape[0], (i+1)/services.shape[0]]},
                    title={'text': service['service_name']},
                    gauge={
                        'axis': {'range': [None, 1]},
                        'bar': {'color': color},
                        'steps': [
                            {'range': [0, 1], 'color': "lightgray"}
                        ],
                        'threshold': {
                            'line': {'color': "red", 'width': 4},
                            'thickness': 0.75,
                            'value': 0.5
                        }
                    }
                ))
            
            fig_services.update_layout(height=400, template="plotly_white")
            st.plotly_chart(fig_services, use_container_width=True)
    
    with col2:
        st.markdown("##### èµ„æºä½¿ç”¨æƒ…å†µ")
        resource_data = get_resource_usage()
        if not resource_data.empty:
            fig_resource = go.Figure()
            
            fig_resource.add_trace(go.Scatter(
                x=resource_data['timestamp'],
                y=resource_data['cpu_usage'],
                mode='lines',
                name='CPUä½¿ç”¨ç‡',
                line=dict(color='#1f77b4')
            ))
            
            fig_resource.add_trace(go.Scatter(
                x=resource_data['timestamp'],
                y=resource_data['memory_usage'],
                mode='lines',
                name='å†…å­˜ä½¿ç”¨ç‡',
                line=dict(color='#ff7f0e')
            ))
            
            fig_resource.update_layout(
                title="ç³»ç»Ÿèµ„æºä½¿ç”¨è¶‹åŠ¿",
                xaxis_title="æ—¶é—´",
                yaxis_title="ä½¿ç”¨ç‡ (%)",
                height=400,
                template="plotly_white"
            )
            st.plotly_chart(fig_resource, use_container_width=True)
    
    # æ•°æ®åº“æ€§èƒ½æŒ‡æ ‡
    st.markdown("##### æ•°æ®åº“æ€§èƒ½")
    db_metrics = get_database_metrics()
    if not db_metrics.empty:
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æŸ¥è¯¢å“åº”æ—¶é—´", f"{db_metrics['avg_query_time'].iloc[0]:.2f}ms")
        with col2:
            st.metric("è¿æ¥æ•°", f"{db_metrics['active_connections'].iloc[0]}")
        with col3:
            st.metric("ç¼“å­˜å‘½ä¸­ç‡", f"{db_metrics['cache_hit_rate'].iloc[0]:.1f}%")
        with col4:
            st.metric("æ…¢æŸ¥è¯¢æ•°", db_metrics['slow_queries'].iloc[0])

def render_runtime_logs():
    """æ¸²æŸ“è¿è¡Œæ—¥å¿—"""
    st.subheader("ğŸ“ ç³»ç»Ÿè¿è¡Œæ—¥å¿—")
    
    # æ—¥å¿—ç­›é€‰
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        log_level = st.selectbox("æ—¥å¿—çº§åˆ«", ["å…¨éƒ¨", "INFO", "WARNING", "ERROR", "DEBUG"])
    with col2:
        service_filter = st.selectbox("æœåŠ¡æ¨¡å—", ["å…¨éƒ¨", "æ•°æ®é‡‡é›†", "æ•°æ®å¤„ç†", "æ•°æ®å­˜å‚¨", "APIæœåŠ¡"])
    with col3:
        time_range = st.selectbox("æ—¶é—´èŒƒå›´", ["æœ€è¿‘1å°æ—¶", "æœ€è¿‘6å°æ—¶", "æœ€è¿‘24å°æ—¶", "æœ€è¿‘7å¤©"])
    with col4:
        search_keyword = st.text_input("æœç´¢å…³é”®è¯", placeholder="è¾“å…¥å…³é”®è¯æœç´¢")
    
    # è·å–æ—¥å¿—æ•°æ®
    log_df = get_system_logs()
    
    if not log_df.empty:
        # åº”ç”¨ç­›é€‰
        if log_level != "å…¨éƒ¨":
            log_df = log_df[log_df['level'] == log_level]
        if service_filter != "å…¨éƒ¨":
            log_df = log_df[log_df['service'] == service_filter]
        if search_keyword:
            log_df = log_df[log_df['message'].str.contains(search_keyword, case=False, na=False)]
        
        st.markdown(f"**ç­›é€‰ç»“æœ**: å…± `{len(log_df)}` æ¡æ—¥å¿—")
        
        # æ—¥å¿—çº§åˆ«åˆ†å¸ƒ
        col1, col2 = st.columns([1, 2])
        with col1:
            level_counts = log_df['level'].value_counts()
            fig_level = px.pie(
                values=level_counts.values,
                names=level_counts.index,
                title="æ—¥å¿—çº§åˆ«åˆ†å¸ƒ",
                color_discrete_map={'ERROR': '#DC143C', 'WARNING': '#FFD700', 'INFO': '#1f77b4', 'DEBUG': '#2E8B57'}
            )
            fig_level.update_layout(height=300)
            st.plotly_chart(fig_level, use_container_width=True)
        
        with col2:
            # å®æ—¶æ—¥å¿—æµ
            st.markdown("##### å®æ—¶æ—¥å¿—æµ")
            
            # æ—¥å¿—è¡¨æ ¼
            st.dataframe(
                log_df.head(20),  # æ˜¾ç¤ºæœ€è¿‘20æ¡
                column_config={
                    "timestamp": st.column_config.DatetimeColumn("æ—¶é—´", format="HH:mm:ss"),
                    "level": st.column_config.TextColumn("çº§åˆ«", width="small"),
                    "service": st.column_config.TextColumn("æœåŠ¡", width="medium"),
                    "message": st.column_config.TextColumn("æ¶ˆæ¯", width="large")
                },
                use_container_width=True,
                hide_index=True
            )
        
        # æ—¥å¿—å¯¼å‡º
        if st.button("ğŸ“¥ å¯¼å‡ºæ—¥å¿—"):
            csv_data = log_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="ä¸‹è½½CSVæ—¥å¿—æ–‡ä»¶",
                data=csv_data,
                file_name=f"system_logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime='text/csv'
            )
    else:
        st.info("æš‚æ— æ—¥å¿—æ•°æ®")

def render_error_monitoring():
    """æ¸²æŸ“å¼‚å¸¸ç›‘æ§"""
    st.subheader("âš ï¸ å¼‚å¸¸ç›‘æ§ä¸å‘Šè­¦")
    
    # å¼‚å¸¸ç»Ÿè®¡
    error_stats = get_error_statistics()
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ä»Šæ—¥å¼‚å¸¸", error_stats.get('today_errors', 0), f"+{error_stats.get('error_increase', 0)} vs æ˜¨æ—¥")
    with col2:
        st.metric("å¾…å¤„ç†", error_stats.get('pending_errors', 0), f"ä¼˜å…ˆå¤„ç†")
    with col3:
        st.metric("å·²è§£å†³", error_stats.get('resolved_errors', 0), f"å¤„ç†ç‡ {error_stats.get('resolution_rate', 0):.1f}%")
    with col4:
        st.metric("å¹³å‡è§£å†³æ—¶é—´", f"{error_stats.get('avg_resolution_time', 0)}åˆ†é’Ÿ")
    
    st.divider()
    
    # å¼‚å¸¸è¶‹åŠ¿å›¾
    col1, col2 = st.columns(2)
    with col1:
        error_trend = get_error_trend()
        if not error_trend.empty:
            fig_trend = px.line(
                error_trend,
                x='date',
                y='error_count',
                title="å¼‚å¸¸è¶‹åŠ¿ï¼ˆè¿‘7å¤©ï¼‰",
                labels={'date': 'æ—¥æœŸ', 'error_count': 'å¼‚å¸¸æ•°é‡'}
            )
            fig_trend.update_layout(height=300)
            st.plotly_chart(fig_trend, use_container_width=True)
    
    with col2:
        error_types = get_error_types()
        if not error_types.empty:
            fig_types = px.bar(
                error_types,
                x='error_type',
                y='count',
                title="å¼‚å¸¸ç±»å‹åˆ†å¸ƒ",
                labels={'error_type': 'å¼‚å¸¸ç±»å‹', 'count': 'æ•°é‡'}
            )
            fig_types.update_layout(height=300)
            st.plotly_chart(fig_types, use_container_width=True)
    
    # å¼‚å¸¸è¯¦æƒ…åˆ—è¡¨
    st.markdown("##### å¼‚å¸¸è¯¦æƒ…")
    error_logs = get_error_logs()
    if not error_logs.empty:
        st.dataframe(
            error_logs,
            column_config={
                "timestamp": st.column_config.DatetimeColumn("å‘ç”Ÿæ—¶é—´", format="MM-DD HH:mm:ss"),
                "error_type": st.column_config.TextColumn("å¼‚å¸¸ç±»å‹", width="medium"),
                "severity": st.column_config.SelectboxColumn("ä¸¥é‡ç¨‹åº¦", options=["ä½", "ä¸­", "é«˜", "ç´§æ€¥"]),
                "message": st.column_config.TextColumn("å¼‚å¸¸ä¿¡æ¯", width="large"),
                "status": st.column_config.SelectboxColumn("å¤„ç†çŠ¶æ€", options=["å¾…å¤„ç†", "å¤„ç†ä¸­", "å·²è§£å†³"]),
                "assigned_to": st.column_config.TextColumn("è´Ÿè´£äºº", width="small")
            },
            use_container_width=True,
            hide_index=True
        )
    else:
        st.success("âœ… å½“å‰æ— å¼‚å¸¸è®°å½•")

def render_performance_analysis():
    """æ¸²æŸ“æ€§èƒ½åˆ†æ"""
    st.subheader("ğŸ“ˆ ç³»ç»Ÿæ€§èƒ½åˆ†æ")
    
    # æ€§èƒ½æŒ‡æ ‡æ¦‚è§ˆ
    perf_metrics = get_performance_metrics()
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å¹³å‡å“åº”æ—¶é—´", f"{perf_metrics.get('avg_response_time', 0):.2f}ms")
    with col2:
        st.metric("è¯·æ±‚æˆåŠŸç‡", f"{perf_metrics.get('success_rate', 0):.1f}%")
    with col3:
        st.metric("å¹¶å‘ç”¨æˆ·æ•°", perf_metrics.get('concurrent_users', 0))
    
    st.divider()
    
    # å“åº”æ—¶é—´è¶‹åŠ¿
    response_trend = get_response_time_trend()
    if not response_trend.empty:
        fig_response = px.line(
            response_trend,
            x='timestamp',
            y='response_time',
            title="APIå“åº”æ—¶é—´è¶‹åŠ¿",
            labels={'timestamp': 'æ—¶é—´', 'response_time': 'å“åº”æ—¶é—´ (ms)'}
        )
        fig_response.update_layout(height=350)
        st.plotly_chart(fig_response, use_container_width=True)
    
    # ååé‡åˆ†æ
    throughput_data = get_throughput_analysis()
    if not throughput_data.empty:
        col1, col2 = st.columns(2)
        with col1:
            fig_throughput = px.bar(
                throughput_data,
                x='hour',
                y='request_count',
                title="æ¯å°æ—¶è¯·æ±‚é‡åˆ†å¸ƒ",
                labels={'hour': 'å°æ—¶', 'request_count': 'è¯·æ±‚æ•°'}
            )
            fig_throughput.update_layout(height=300)
            st.plotly_chart(fig_throughput, use_container_width=True)
        
        with col2:
            # APIç«¯ç‚¹æ€§èƒ½
            endpoint_performance = get_endpoint_performance()
            if not endpoint_performance.empty:
                fig_endpoint = px.scatter(
                    endpoint_performance,
                    x='avg_response_time',
                    y='request_count',
                    size='error_rate',
                    color='endpoint',
                    title="APIç«¯ç‚¹æ€§èƒ½åˆ†æ",
                    labels={'avg_response_time': 'å¹³å‡å“åº”æ—¶é—´', 'request_count': 'è¯·æ±‚æ•°', 'error_rate': 'é”™è¯¯ç‡'}
                )
                fig_endpoint.update_layout(height=300)
                st.plotly_chart(fig_endpoint, use_container_width=True)

def render_log_search():
    """æ¸²æŸ“æ—¥å¿—æŸ¥è¯¢"""
    st.subheader("ğŸ” é«˜çº§æ—¥å¿—æŸ¥è¯¢")
    
    with st.form("advanced_search"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### æŸ¥è¯¢æ¡ä»¶")
            start_time = st.datetime_input("å¼€å§‹æ—¶é—´", value=datetime.now() - timedelta(hours=24))
            end_time = st.datetime_input("ç»“æŸæ—¶é—´", value=datetime.now())
            selected_levels = st.multiselect(
                "æ—¥å¿—çº§åˆ«",
                ["INFO", "WARNING", "ERROR", "DEBUG"],
                default=["WARNING", "ERROR"]
            )
            selected_services = st.multiselect(
                "æœåŠ¡æ¨¡å—",
                ["æ•°æ®é‡‡é›†", "æ•°æ®å¤„ç†", "æ•°æ®å­˜å‚¨", "APIæœåŠ¡"],
                default=["æ•°æ®é‡‡é›†", "æ•°æ®å¤„ç†"]
            )
        
        with col2:
            st.markdown("#### é«˜çº§é€‰é¡¹")
            keyword = st.text_input("å…³é”®è¯æœç´¢", placeholder="æ”¯æŒæ­£åˆ™è¡¨è¾¾å¼")
            exclude_keyword = st.text_input("æ’é™¤å…³é”®è¯", placeholder="æ’é™¤åŒ…å«æ­¤å…³é”®è¯çš„æ—¥å¿—")
            user_filter = st.text_input("ç”¨æˆ·ç­›é€‰", placeholder="æŒ‰ç”¨æˆ·IDç­›é€‰")
            session_filter = st.text_input("ä¼šè¯ç­›é€‰", placeholder="æŒ‰ä¼šè¯IDç­›é€‰")
        
        max_results = st.number_input("æœ€å¤§ç»“æœæ•°", min_value=10, max_value=1000, value=100)
        
        search_button = st.form_submit_button("ğŸ” æ‰§è¡ŒæŸ¥è¯¢", type="primary")
    
    if search_button:
        with st.spinner("æ­£åœ¨æœç´¢æ—¥å¿—..."):
            # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„æœç´¢å‡½æ•°
            search_results = perform_advanced_log_search(
                start_time, end_time, selected_levels, selected_services,
                keyword, exclude_keyword, user_filter, session_filter, max_results
            )
            
            if not search_results.empty:
                st.success(f"âœ… æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(search_results)} æ¡è®°å½•")
                
                # æœç´¢ç»“æœç»Ÿè®¡
                col1, col2, col3 = st.columns(3)
                with col1:
                    level_dist = search_results['level'].value_counts()
                    st.write("**çº§åˆ«åˆ†å¸ƒ:**")
                    for level, count in level_dist.items():
                        st.write(f"- {level}: {count}")
                
                with col2:
                    service_dist = search_results['service'].value_counts()
                    st.write("**æœåŠ¡åˆ†å¸ƒ:**")
                    for service, count in service_dist.head(5).items():
                        st.write(f"- {service}: {count}")
                
                with col3:
                    st.write("**æ—¶é—´åˆ†å¸ƒ:**")
                    hourly_dist = search_results.groupby(search_results['timestamp'].dt.hour).size()
                    for hour, count in hourly_dist.items():
                        st.write(f"- {hour:02d}:00 - {count} æ¡")
                
                # è¯¦ç»†ç»“æœ
                st.dataframe(
                    search_results,
                    column_config={
                        "timestamp": st.column_config.DatetimeColumn("æ—¶é—´", format="YYYY-MM-DD HH:mm:ss"),
                        "level": st.column_config.TextColumn("çº§åˆ«", width="small"),
                        "service": st.column_config.TextColumn("æœåŠ¡", width="medium"),
                        "user": st.column_config.TextColumn("ç”¨æˆ·", width="small"),
                        "session": st.column_config.TextColumn("ä¼šè¯", width="medium"),
                        "message": st.column_config.TextColumn("æ¶ˆæ¯", width="large")
                    },
                    use_container_width=True,
                    hide_index=True
                )
                
                # å¯¼å‡ºæœç´¢ç»“æœ
                csv_data = search_results.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ğŸ“¥ å¯¼å‡ºæœç´¢ç»“æœ",
                    data=csv_data,
                    file_name=f"log_search_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime='text/csv'
                )
            else:
                st.warning("âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ—¥å¿—è®°å½•")

# è¾…åŠ©å‡½æ•°
@st.cache_data(ttl=60)
def get_system_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    return {
        'db_status': 'æ­£å¸¸',
        'db_pool_size': 8,
        'db_pool_max': 20,
        'collection_delay': 12,
        'delay_change': -3,
        'error_count': 5,
        'resolved_errors': 8,
        'data_throughput': 45,
        'throughput_change': 12.5
    }

@st.cache_data(ttl=300)
def get_service_status():
    """è·å–æœåŠ¡çŠ¶æ€"""
    data = {
        'service_name': ['æ•°æ®é‡‡é›†æœåŠ¡', 'æ•°æ®å¤„ç†æœåŠ¡', 'æ•°æ®å­˜å‚¨æœåŠ¡', 'APIç½‘å…³', 'Webå‰ç«¯'],
        'status': ['è¿è¡Œä¸­', 'è¿è¡Œä¸­', 'è¿è¡Œä¸­', 'è¿è¡Œä¸­', 'è¿è¡Œä¸­']
    }
    return pd.DataFrame(data)

@st.cache_data(ttl=60)
def get_resource_usage():
    """è·å–èµ„æºä½¿ç”¨æƒ…å†µ"""
    import pandas as pd
    times = pd.date_range(end=datetime.now(), periods=60, freq='min')
    cpu_usage = [30 + i*0.5 + (i%5)*2 for i in range(60)]
    memory_usage = [45 + i*0.3 + (i%7)*1.5 for i in range(60)]
    return pd.DataFrame({'timestamp': times, 'cpu_usage': cpu_usage, 'memory_usage': memory_usage})

@st.cache_data(ttl=300)
def get_database_metrics():
    """è·å–æ•°æ®åº“æ€§èƒ½æŒ‡æ ‡"""
    data = {
        'avg_query_time': [2.5],
        'active_connections': [15],
        'cache_hit_rate': [94.2],
        'slow_queries': [3]
    }
    return pd.DataFrame(data)

@st.cache_data(ttl=300)
def get_error_statistics():
    """è·å–å¼‚å¸¸ç»Ÿè®¡"""
    return {
        'today_errors': 12,
        'error_increase': 3,
        'pending_errors': 5,
        'resolved_errors': 18,
        'resolution_rate': 78.3,
        'avg_resolution_time': 45
    }

@st.cache_data(ttl=300)
def get_error_trend():
    """è·å–å¼‚å¸¸è¶‹åŠ¿"""
    import pandas as pd
    dates = pd.date_range(end=datetime.now(), periods=7, freq='D')
    counts = [8, 12, 6, 15, 9, 11, 12]
    return pd.DataFrame({'date': dates, 'error_count': counts})

@st.cache_data(ttl=300)
def get_error_types():
    """è·å–å¼‚å¸¸ç±»å‹"""
    data = {
        'error_type': ['æ•°æ®åº“è¿æ¥', 'ç½‘ç»œè¶…æ—¶', 'æ•°æ®æ ¼å¼', 'æƒé™éªŒè¯', 'ç³»ç»Ÿèµ„æº'],
        'count': [3, 4, 2, 1, 2]
    }
    return pd.DataFrame(data)

@st.cache_data(ttl=300)
def get_response_time_trend():
    """è·å–å“åº”æ—¶é—´è¶‹åŠ¿"""
    import pandas as pd
    times = pd.date_range(end=datetime.now(), periods=24, freq='H')
    response_times = [15 + i*0.2 + (i%4)*3 for i in range(24)]
    return pd.DataFrame({'timestamp': times, 'response_time': response_times})

@st.cache_data(ttl=300)
def get_throughput_analysis():
    """è·å–ååé‡åˆ†æ"""
    data = {
        'hour': list(range(24)),
        'request_count': [120, 95, 80, 65, 70, 150, 280, 350, 420, 380, 350, 320, 
                         340, 360, 390, 410, 380, 320, 280, 220, 180, 160, 140, 130]
    }
    return pd.DataFrame(data)

@st.cache_data(ttl=300)
def get_endpoint_performance():
    """è·å–ç«¯ç‚¹æ€§èƒ½"""
    data = {
        'endpoint': ['/api/vitals', '/api/patients', '/api/devices', '/api/logs', '/api/mappings'],
        'avg_response_time': [12, 18, 25, 15, 22],
        'request_count': [1250, 890, 450, 320, 180],
        'error_rate': [0.5, 1.2, 0.8, 0.3, 1.5]
    }
    return pd.DataFrame(data)

def perform_advanced_log_search(start_time, end_time, levels, services, keyword, exclude, user, session, max_results):
    """æ‰§è¡Œé«˜çº§æ—¥å¿—æœç´¢"""
    # æ¨¡æ‹Ÿæœç´¢ç»“æœ
    import pandas as pd
    import random
    
    results = []
    for i in range(min(max_results, 50)):  # æœ€å¤šè¿”å›50æ¡æ¨¡æ‹Ÿæ•°æ®
        timestamp = start_time + timedelta(minutes=random.randint(0, int((end_time - start_time).total_seconds() / 60)))
        results.append({
            'timestamp': timestamp,
            'level': random.choice(levels) if levels else random.choice(['INFO', 'WARNING', 'ERROR']),
            'service': random.choice(services) if services else random.choice(['æ•°æ®é‡‡é›†', 'æ•°æ®å¤„ç†']),
            'user': user if user else f"user_{random.randint(1, 10)}",
            'session': session if session else f"session_{random.randint(1000, 9999)}",
            'message': f"æ¨¡æ‹Ÿæ—¥å¿—æ¶ˆæ¯ {i+1} - {keyword if keyword else 'ç³»ç»Ÿè¿è¡Œæ­£å¸¸'}"
        })
    
    return pd.DataFrame(results)